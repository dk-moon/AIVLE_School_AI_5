{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **공공데이터를 활용한 미세먼지 농도 예측**\n",
    "---\n",
    "## Step 3. 머신러닝 모델링"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "from statsmodels.graphics.mosaicplot import mosaic\n",
    "from scipy import stats as spst\n",
    "import statsmodels.api as sm\n",
    "import joblib\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple Mac 기준 코드\n",
    "plt.rc('font', family='AppleGothic')\n",
    "sns.set(font=\"AppleGothic\", \n",
    "        rc={\"axes.unicode_minus\":False}, # 마이너스 부호 깨짐 현상 해결\n",
    "        style='darkgrid')\n",
    "\n",
    "# # Window 기준 코드\n",
    "# plt.rc('font', family='Malgun Gothic')\n",
    "# sns.set(font=\"Malgun Gothic\",#\"NanumGothicCoding\", \n",
    "#         rc={\"axes.unicode_minus\":False}, # 마이너스 부호 깨짐 현상 해결\n",
    "#         style='darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv('./train_x.csv')\n",
    "train_y = pd.read_csv('./train_y.csv')\n",
    "test_x = pd.read_csv('./test_x.csv')\n",
    "test_y = pd.read_csv('./test_y.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = MinMaxScaler()\n",
    "s_scaler = StandardScaler()\n",
    "\n",
    "train_x_mm = mm_scaler.fit_transform(train_x)\n",
    "test_x_mm = mm_scaler.transform(test_x)\n",
    "\n",
    "train_x_s = s_scaler.fit_transform(train_x)\n",
    "test_x_s = s_scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=5)\n",
    "\n",
    "train_x_pca = pca.fit_transform(train_x)\n",
    "train_x_pca = pd.DataFrame(data=train_x_pca, columns = ['pca_1','pca_2','pca_3','pca_4','pca_5'])\n",
    "\n",
    "test_x_pca = pca.transform(test_x)\n",
    "test_x_pca = pd.DataFrame(data=test_x_pca, columns = ['pca_1','pca_2','pca_3','pca_4','pca_5'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_trainer(X_train, y_train, X_test, y_test):\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    y_pred = lr_model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    result = [mse, rmse, mae, r2]\n",
    "    return lr_model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE | RMSE | MAE | R2\n",
      "[102.31460068904832, 10.115068002195947, 5.994888610543269, 0.8973186151384074]\n",
      "[102.31460068906821, 10.115068002196931, 5.994888610543184, 0.8973186151383874]\n",
      "[102.31460068906831, 10.115068002196937, 5.99488861054319, 0.8973186151383873]\n",
      "[218.9634034279007, 14.797412051703525, 9.251165867361273, 0.780251642027949]\n"
     ]
    }
   ],
   "source": [
    "org_lr_model, org_result = lr_trainer(train_x, train_y, test_x, test_y)\n",
    "mm_lr_model, mm_result = lr_trainer(train_x_mm, train_y, test_x_mm, test_y)\n",
    "s_lr_model, s_result = lr_trainer(train_x_s, train_y, test_x_s, test_y)\n",
    "pca_lr_model, pca_result = lr_trainer(train_x_pca, train_y, test_x_pca, test_y)\n",
    "\n",
    "print(\"MSE | RMSE | MAE | R2\")\n",
    "print(org_result)\n",
    "print(mm_result)\n",
    "print(s_result)\n",
    "print(pca_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(org_lr_model, 'model_lr_org.pkl')\n",
    "# joblib.dump(mm_lr_model, 'model_lr_mm.pkl')\n",
    "# joblib.dump(s_lr_model, 'model_lr_s.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_trainer(X_train, y_train, X_test, y_test):\n",
    "    rf_model = RFR(max_depth=7)\n",
    "    rf_model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    result = [mse, rmse, mae, r2]\n",
    "    return rf_model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_rf_model, org_result = rf_trainer(train_x, train_y, test_x, test_y)\n",
    "mm_rf_model, mm_result = rf_trainer(train_x_mm, train_y, test_x_mm, test_y)\n",
    "s_rf_model, s_result = rf_trainer(train_x_s, train_y, test_x_s, test_y)\n",
    "\n",
    "print(\"MSE | RMSE | MAE | R2\")\n",
    "print(org_result)\n",
    "print(mm_result)\n",
    "print(s_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(org_rf_model, 'model_lr_org.pkl')\n",
    "# joblib.dump(mm_rf_model, 'model_lr_mm.pkl')\n",
    "# joblib.dump(s_rf_model, 'model_lr_s.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gbr_trainer(X_train, y_train, X_test, y_test):\n",
    "    gbr_model = GBR()\n",
    "    gbr_model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = gbr_model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    result = [mse, rmse, mae, r2]\n",
    "    return gbr_model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_gbr_model, org_result = gbr_trainer(train_x, train_y, test_x, test_y)\n",
    "mm_gbr_model, mm_result = gbr_trainer(train_x_mm, train_y, test_x_mm, test_y)\n",
    "s_gbr_model, s_result = gbr_trainer(train_x_s, train_y, test_x_s, test_y)\n",
    "\n",
    "print(\"MSE | RMSE | MAE | R2\")\n",
    "print(org_result)\n",
    "print(mm_result)\n",
    "print(s_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(org_gbr_model, 'model_lr_org.pkl')\n",
    "# joblib.dump(mm_gbr_model, 'model_lr_mm.pkl')\n",
    "# joblib.dump(s_gbr_model, 'model_lr_s.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.barh(y=list(train_x), width=org_gbr_model.feature_importances_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_trainer(X_train, y_train, X_test, y_test):\n",
    "    xgb_model = XGBRegressor(objective ='reg:squarederror')\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    result = [mse, rmse, mae, r2]\n",
    "    return xgb_model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_xgb_model, org_result = xgb_trainer(train_x, train_y, test_x, test_y)\n",
    "mm_xgb_model, mm_result = xgb_trainer(train_x_mm, train_y, test_x_mm, test_y)\n",
    "s_xgb_model, s_result = xgb_trainer(train_x_s, train_y, test_x_s, test_y)\n",
    "\n",
    "print(\"MSE | RMSE | MAE | R2\")\n",
    "print(org_result)\n",
    "print(mm_result)\n",
    "print(s_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_trainer(X_train, y_train, X_test, y_test):\n",
    "    lgbm_model = LGBMRegressor()\n",
    "    lgbm_model.fit(X_train, y_train.values.ravel())\n",
    "    y_pred = lgbm_model.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    result = [mse, rmse, mae, r2]\n",
    "    return lgbm_model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_lgbm_model, org_result = lgbm_trainer(train_x, train_y, test_x, test_y)\n",
    "mm_lgbm_model, mm_result = lgbm_trainer(train_x_mm, train_y, test_x_mm, test_y)\n",
    "s_lgbm_model, s_result = lgbm_trainer(train_x_s, train_y, test_x_s, test_y)\n",
    "\n",
    "print(\"MSE | RMSE | MAE | R2\")\n",
    "print(org_result)\n",
    "print(mm_result)\n",
    "print(s_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
